---
title: FFmpeg解码本地视频播放（配合SDL2）一
id: 70
categories:
  - 未分类
date: 2016-09-13 14:56:08
tags:
---

一、FFmpeg编译

1、下载源码  [https://github.com/FFmpeg/FFmpeg](https://github.com/FFmpeg/FFmpeg)

2、编译环境 ubuntu14.04 32位

2、编译脚本  arm.sh
<pre class="html">#!/bin/bash
export TMPDIR=$HOME/ffmpeg_temp
NDK=$HOME/tools/android-ndk-r10e
SYSROOT=$NDK/platforms/android-16/arch-arm/
TOOLCHAIN=$NDK/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86
CPU=arm
PREFIX=$HOME/ffmpeg-so/arm/
ADDI_CFLAGS="-marm"
function build_one
{
./configure \
--prefix=$PREFIX \
--enable-shared \
--disable-static \
--disable-doc \
--disable-ffmpeg \
--disable-ffplay \
--disable-ffprobe \
--disable-ffserver \
--disable-doc \
--disable-symver \
--enable-small \
--cross-prefix=$TOOLCHAIN/bin/arm-linux-androideabi- \
--target-os=linux \
--arch=arm \
--enable-cross-compile \
--sysroot=$SYSROOT \
--extra-cflags="-Os -fpic $ADDI_CFLAGS" \
--extra-ldflags="$ADDI_LDFLAGS" \
$ADDITIONAL_CONFIGURE_FLAG
make clean
make
make install
}
build_one</pre>
x86版本只需要修改
<pre class="html">export TMPDIR=$HOME/ffmpeg_temp

NDK=$HOME/tools/android-ndk-r10e
SYSROOT=$NDK/platforms/android-16/arch-x86/
TOOLCHAIN=$NDK/toolchains/x86-4.9/prebuilt/linux-x86

CPU=x86
PREFIX=$HOME/ffmpeg-so/x86/</pre>
3、将上边的编译脚本放到ffmpeg根目录执行，生成的so在上边PREFIX目录下。

二、SDL

1、下载最新源码2.0.4，android工程是android-project，导入到eclipse中。

2、sdl的jni中最终会调用main方法，为了方便，直接在sdl的android   demo中修改，我的项目目录

![](http://img.blog.csdn.net/20160518112021065?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

include放ffmpeg的头文件

3、创建main.c文件
<pre class="html">#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;time.h&gt;
#include &lt;jni.h&gt;

#include "libavcodec/avcodec.h"
#include "libavformat/avformat.h"
#include "libswscale/swscale.h"
#include "SDL.h"
#include &lt;android/log.h&gt;
#define LOG_TAG "SDL"
#define SDL_AUDIO_BUFFER_SIZE 1024
#define MAX_AUDIO_FRAME_SIZE 192000

#define MAX_AUDIOQ_SIZE (5 * 16 * 1024)
#define MAX_VIDEOQ_SIZE (5 * 256 * 1024)

#define FF_ALLOC_EVENT   (SDL_USEREVENT)
#define FF_REFRESH_EVENT (SDL_USEREVENT + 1)
#define FF_QUIT_EVENT (SDL_USEREVENT + 2)

#define VIDEO_PICTURE_QUEUE_SIZE 1
#define LOGE(...)  __android_log_print(ANDROID_LOG_ERROR,LOG_TAG,__VA_ARGS__)

typedef struct Sprite {
	SDL_Texture* texture;
	Uint16 w;
	Uint16 h;
} Sprite;

typedef struct VideoDecoder {
	AVFormatContext *pFormatCtx;
	AVCodec *codec;
	AVCodecContext *codec_ctx;
	struct SwsContext *convert_ctx;
	AVFrame *pFrame;
	AVFrame *pFrameYUV;
	AVPacket *packet;
	SDL_Window *screen;
	SDL_Renderer *renderer;
	SDL_Texture *bmp;
	SDL_Rect rect;
	SDL_Event event;
} VideoDecoder;

typedef struct AudioDecoder {
	AVCodec *codec;
	AVCodecContext *codec_ctx;
	AVPacket *aPacket;
	AVFrame *aFrame;
	AVPacketList *first_pkt, *last_pkt;
	int nb_packets;
	int size;
	SDL_mutex *mutex;
	SDL_cond *cond;
	SDL_AudioSpec desired, obtained; //SDL_OpenAudio需要传递的参数，1期望的参数2实际音频设备的参数，一般传空就好
} AudioDecoder;
int quit = 0;
static void av_log_callback(void *ptr, int level, const char *fmt, __va_list vl) {
	static char line[1024] = { 0 };
	vsnprintf(line, sizeof(line), fmt, vl);
//	LOGE("av_log_callback : %s", line);
}

JNIEXPORT jint JNI_OnLoad(JavaVM *vm, void *reserved) {
	av_register_all();
	av_log_set_callback(av_log_callback);

	return JNI_VERSION_1_4;
}
/* Adapted from SDL's testspriteminimal.c */
Sprite LoadSprite(const char* file, SDL_Renderer* renderer) {
	Sprite result;
	result.texture = NULL;
	result.w = 0;
	result.h = 0;

	SDL_Surface* temp;

	/* Load the sprite image */
	temp = SDL_LoadBMP(file);
	if (temp == NULL) {
		fprintf(stderr, "Couldn't load %s: %s\n", file, SDL_GetError());
		return result;
	}
	result.w = temp-&gt;w;
	result.h = temp-&gt;h;

	/* Create texture from the image */
	result.texture = SDL_CreateTextureFromSurface(renderer, temp);
	if (!result.texture) {
		fprintf(stderr, "Couldn't create texture: %s\n", SDL_GetError());
		SDL_FreeSurface(temp);
		return result;
	}
	SDL_FreeSurface(temp);

	return result;
}

void draw(SDL_Window* window, SDL_Renderer* renderer, const Sprite sprite) {
	int w, h;
	SDL_GetWindowSize(window, &amp;w, &amp;h);
	SDL_Rect destRect = { w / 2 - sprite.w / 2, h / 2 - sprite.h / 2, sprite.w,
			sprite.h };
	/* Blit the sprite onto the screen */
	SDL_RenderCopy(renderer, sprite.texture, NULL, &amp;destRect);
}

void decodeVideo() {

}

int decodeAudio(AudioDecoder *audioCtx, AVPacket *pkt) {
	LOGE("decodeAudio()=========start%d",audioCtx-&gt;aPacket-&gt;size);
	AVPacketList *pkt1;
	if (av_dup_packet(pkt) &lt; 0) {
		return -1;
	}
	LOGE("decodeAudio()=========start1");
	pkt1 = (AVPacketList *) av_malloc(sizeof(AVPacketList));
	if (!pkt1)
		return -1;
	pkt1-&gt;pkt = *pkt;
	pkt1-&gt;next = NULL;
	SDL_LockMutex(audioCtx-&gt;mutex);
	LOGE("decodeAudio()=========start2");
	if (!audioCtx-&gt;last_pkt)
		audioCtx-&gt;first_pkt = pkt1;
	else
		audioCtx-&gt;last_pkt-&gt;next = pkt1;
	audioCtx-&gt;last_pkt = pkt1;
	audioCtx-&gt;nb_packets++;
	audioCtx-&gt;size += pkt1-&gt;pkt.size;
	SDL_CondSignal(audioCtx-&gt;cond);
	SDL_UnlockMutex(audioCtx-&gt;mutex);
	LOGE("decodeAudio()=========end");
	return 0;
}
int audio_decode_frame(AudioDecoder *audioCtx, uint8_t *audio_buf, int buf_size) {
	LOGE("start audio_decode_frame==========");
	AVPacket *pkt = audioCtx-&gt;aPacket;
	if(pkt == NULL)
		LOGE("start audio_decode_frame==========pkt == NULL");
	uint8_t *audio_pkt_data = NULL;
	int audio_pkt_size = 0;
	int len1, data_size;
	int framFinish = 0;
	LOGE("start audio_decode_frame==========1 packet size:%d",pkt-&gt;size);
	audioCtx-&gt;aFrame = av_frame_alloc();
	for (;;) {
		while (audio_pkt_size &gt; 0) {
			data_size = buf_size;
			LOGE("start audio_decode_frame==========2");
			len1 = avcodec_decode_audio4(audioCtx-&gt;codec_ctx, audioCtx-&gt;aFrame,
					&amp;framFinish, audioCtx-&gt;aPacket);
			LOGE("decode audio ...");
			if (len1 &lt; 0) { /* if error, skip frame */
				audio_pkt_size = 0;
				break;
			}
			audio_pkt_data += len1;
			audio_pkt_size -= len1;
			if (data_size &lt;= 0) { /* No data yet, get more frames */
				continue;
			} /* We have data, return it and come back for more later */
			return data_size;
		}
		if (pkt-&gt;data)
			av_free_packet(pkt);
		if (quit) {
			return -1;
		}
		if (packet_queue_get(&amp;audioCtx, 1) &lt; 0) {
			return -1;
		}
		LOGE("audio_decode_frame ======aaaaaa");
		audio_pkt_data = pkt-&gt;data;
		audio_pkt_size = pkt-&gt;size;
	}
	return 0;
}

int packet_queue_get(AudioDecoder *q, int block) {
	AVPacket *pkt = q-&gt;aPacket;
	AVPacketList *pkt1;
	int ret;
	SDL_LockMutex(q-&gt;mutex);
	for (;;) {
		if (quit) {
			ret = -1;
			break;
		}
		pkt1 = q-&gt;first_pkt;
		if (pkt1) {
			q-&gt;first_pkt = pkt1-&gt;next;
			if (!q-&gt;first_pkt)
				q-&gt;last_pkt = NULL;
			q-&gt;nb_packets--;
			q-&gt;size -= pkt1-&gt;pkt.size;
			*pkt = pkt1-&gt;pkt;
			av_free(pkt1);
			ret = 1;
			break;
		} else if (!block) {
			ret = 0;
			break;
		} else {
			SDL_CondWait(q-&gt;cond, q-&gt;mutex);
		}
	}
	SDL_UnlockMutex(q-&gt;mutex);
	return ret;
}
void audio_callback(void *userdata, Uint8 *stream, int len) {
	AudioDecoder *audioCtx = (AudioDecoder *) userdata;
	int len1, audio_size;
	uint8_t audio_buf[(MAX_AUDIO_FRAME_SIZE * 3) / 2];
	unsigned int audio_buf_size = 0;
	unsigned int audio_buf_index = 0;
	while (len &gt; 0) {
		if (audio_buf_index &gt;= audio_buf_size) { /* We have already sent all our data; get more */
			LOGE("audio_decode_frame audioCtx-&gt;pkt:");
			audio_size = audio_decode_frame(audioCtx, audio_buf,
					sizeof(audio_buf));
			if (audio_size &lt; 0) { /* If error, output silence */
				audio_buf_size = 1024; // arbitrary?
				memset(audio_buf, 0, audio_buf_size);
			} else {
				audio_buf_size = audio_size;
			}
			audio_buf_index = 0;
		}
		len1 = audio_buf_size - audio_buf_index;
		if (len1 &gt; len)
			len1 = len;
		memcpy(stream, (uint8_t *) audio_buf + audio_buf_index, len1);
		len -= len1;
		stream += len1;
		audio_buf_index += len1;
	}
}

int main(int argc, char *argv[]) {
	VideoDecoder *videoCtx = (VideoDecoder *) av_mallocz(sizeof(VideoDecoder));
	AudioDecoder *audioCtx = (AudioDecoder *) av_mallocz(sizeof(AudioDecoder));
	audioCtx-&gt;mutex = SDL_CreateMutex();
	audioCtx-&gt;cond = SDL_CreateCond();
	LOGE("SDL init");
	//init sdl2.0
	if (SDL_Init(SDL_INIT_VIDEO | SDL_INIT_AUDIO | SDL_INIT_TIMER)) {
		LOGE("Could not initialize SDL - %s\n", SDL_GetError());
		exit(-1);
	}
	LOGE("SDL init success");

	// Open video file
	if (avformat_open_input(&amp;videoCtx-&gt;pFormatCtx, argv[1], NULL, NULL) != 0)
		return -1;
	LOGE("open video file success.");
	//获取视频流信息
	if (avformat_find_stream_info(videoCtx-&gt;pFormatCtx, NULL) &lt; 0)
		return -1;
	LOGE("stream info success.");
	// Dump information about file onto standard error
	av_dump_format(videoCtx-&gt;pFormatCtx, 0, argv[1], 0);

	int videoIndex = -1, audioIndex = -1, i = 0;
	//获取视频数据的下标值
	for (i = 0; i &lt; videoCtx-&gt;pFormatCtx-&gt;nb_streams; i++) {
		if (videoCtx-&gt;pFormatCtx-&gt;streams[i]-&gt;codec-&gt;codec_type
				== AVMEDIA_TYPE_VIDEO) {
			videoIndex = i;
		}
		if (videoCtx-&gt;pFormatCtx-&gt;streams[i]-&gt;codec-&gt;codec_type
				== AVMEDIA_TYPE_AUDIO) {
			audioIndex = i;
		}
	}
	if (videoIndex == -1 || audioIndex == -1)
		return -1;
	LOGE("拿到解码环境videoIndex:%d,audioIndex:%d",videoIndex,audioIndex);
	//拿到音频解码环境
	audioCtx-&gt;codec_ctx = videoCtx-&gt;pFormatCtx-&gt;streams[audioIndex]-&gt;codec;
	audioCtx-&gt;desired.freq = audioCtx-&gt;codec_ctx-&gt;sample_rate;
	audioCtx-&gt;desired.format = AUDIO_S16SYS;
	audioCtx-&gt;desired.channels = audioCtx-&gt;codec_ctx-&gt;channels;
	audioCtx-&gt;desired.silence = 0;
	audioCtx-&gt;desired.samples = SDL_AUDIO_BUFFER_SIZE;
	audioCtx-&gt;desired.callback = audio_callback;
	audioCtx-&gt;desired.userdata = audioCtx;

	if (SDL_OpenAudio(&amp;audioCtx-&gt;desired, &amp;audioCtx-&gt;obtained) &lt; 0) {
		LOGE("SDL_OpenAudio: %s/n", SDL_GetError());
		return -1;
	}
	//寻找合适的音频解码器
	audioCtx-&gt;codec = avcodec_find_decoder(audioCtx-&gt;codec_ctx-&gt;codec_id);
	if (audioCtx-&gt;codec == NULL) {
		LOGE("Unsupported audio codec! \n");
		return -1;
	}
	//打开音频解码器
	if (avcodec_open2(audioCtx-&gt;codec_ctx, audioCtx-&gt;codec, NULL) &lt; 0) {
		LOGE("Couldn't open audio codec.\n");
		return -1;
	}

	//解码音频先注掉，有问题待修复
//	SDL_PauseAudio(0);

	//拿到视频解码环境
	videoCtx-&gt;codec_ctx = videoCtx-&gt;pFormatCtx-&gt;streams[videoIndex]-&gt;codec;
	//寻找合适的视频解码器
	videoCtx-&gt;codec = avcodec_find_decoder(videoCtx-&gt;codec_ctx-&gt;codec_id);
	if (videoCtx-&gt;codec == NULL) {
		LOGE("Unsupported video codec! \n");
		return -1;
	}
	//打开视频解码器
	if (avcodec_open2(videoCtx-&gt;codec_ctx, videoCtx-&gt;codec, NULL) &lt; 0) {
		LOGE("Couldn't open video codec.\n");
		return -1;
	}
	//AVFrame 获取帧指针
	videoCtx-&gt;pFrame = av_frame_alloc();
	videoCtx-&gt;pFrameYUV = av_frame_alloc();

	if (videoCtx-&gt;pFrameYUV == NULL)
		return -1;

	LOGE("create screen");
	videoCtx-&gt;screen = SDL_CreateWindow("my window",
	SDL_WINDOWPOS_UNDEFINED,
	SDL_WINDOWPOS_UNDEFINED, videoCtx-&gt;codec_ctx-&gt;width,
			videoCtx-&gt;codec_ctx-&gt;height,
			SDL_WINDOW_FULLSCREEN | SDL_WINDOW_OPENGL);
	videoCtx-&gt;renderer = SDL_CreateRenderer(videoCtx-&gt;screen, -1, 0);
	LOGE("create screen success");
	if (!videoCtx-&gt;screen) {
		LOGE("SDL: could not set video mode - exiting\n");
		exit(1);
	}
	videoCtx-&gt;bmp = SDL_CreateTexture(videoCtx-&gt;renderer, SDL_PIXELFORMAT_YV12,
			SDL_TEXTUREACCESS_STREAMING, videoCtx-&gt;codec_ctx-&gt;width,
			videoCtx-&gt;codec_ctx-&gt;height);
	videoCtx-&gt;convert_ctx = sws_getContext(videoCtx-&gt;codec_ctx-&gt;width,
			videoCtx-&gt;codec_ctx-&gt;height, videoCtx-&gt;codec_ctx-&gt;pix_fmt,
			videoCtx-&gt;codec_ctx-&gt;width, videoCtx-&gt;codec_ctx-&gt;height,
			AV_PIX_FMT_YUV420P,
			SWS_BILINEAR,
			NULL,
			NULL,
			NULL);
	LOGE("计算YUV420P所需的内存大小");
	//计算YUV420P所需的内存大小,并分配内存
	int numBytes = avpicture_get_size(AV_PIX_FMT_YUV420P,
			videoCtx-&gt;codec_ctx-&gt;width, videoCtx-&gt;codec_ctx-&gt;height);
	uint8_t* buffer = (uint8_t *) av_malloc(numBytes * sizeof(uint8_t));

	avpicture_fill((AVPicture *) videoCtx-&gt;pFrameYUV, buffer,
			AV_PIX_FMT_YUV420P, videoCtx-&gt;codec_ctx-&gt;width,
			videoCtx-&gt;codec_ctx-&gt;height);
	LOGE("Read frames and save first five frames to disk");
	// Read frames and save first five frames to disk
	i = 0;
	videoCtx-&gt;rect.x = 0;
	videoCtx-&gt;rect.y = 0;
	videoCtx-&gt;rect.w = videoCtx-&gt;codec_ctx-&gt;width;
	videoCtx-&gt;rect.h = videoCtx-&gt;codec_ctx-&gt;height;
	int frameFinished = 0;
	LOGE("开始解码");
	int y_size = videoCtx-&gt;codec_ctx-&gt;width * videoCtx-&gt;codec_ctx-&gt;height;
	videoCtx-&gt;packet = (AVPacket *) malloc(sizeof(AVPacket));
	av_new_packet(videoCtx-&gt;packet, y_size);
	while (av_read_frame(videoCtx-&gt;pFormatCtx, videoCtx-&gt;packet) &gt;= 0) {
		// Is this a packet from the video stream?
//		LOGE("Is this a packet from the video stream :%d",videoCtx-&gt;packet-&gt;stream_index);
		if (videoCtx-&gt;packet-&gt;stream_index == videoIndex) {
			// Decode video frame
			avcodec_decode_video2(videoCtx-&gt;codec_ctx, videoCtx-&gt;pFrame,
					&amp;frameFinished, videoCtx-&gt;packet);
//			LOGE("Did we get a video frame");
			// Did we get a video frame?
			if (frameFinished) {
				LOGE("解码一帧成功");
				sws_scale(videoCtx-&gt;convert_ctx,
						(uint8_t const * const *) videoCtx-&gt;pFrame-&gt;data,
						videoCtx-&gt;pFrame-&gt;linesize, 0,
						videoCtx-&gt;codec_ctx-&gt;height, videoCtx-&gt;pFrameYUV-&gt;data,
						videoCtx-&gt;pFrameYUV-&gt;linesize);
				//计算yuv一行数据占的字节数
				SDL_UpdateTexture(videoCtx-&gt;bmp, &amp;videoCtx-&gt;rect,
						videoCtx-&gt;pFrameYUV-&gt;data[0],
						videoCtx-&gt;pFrameYUV-&gt;linesize[0]);
				SDL_RenderClear(videoCtx-&gt;renderer);
				SDL_RenderCopy(videoCtx-&gt;renderer, videoCtx-&gt;bmp,
						&amp;videoCtx-&gt;rect, &amp;videoCtx-&gt;rect);
				SDL_RenderPresent(videoCtx-&gt;renderer);
			}
			SDL_Delay(50);
			// Free the packet that was allocated by av_read_frame
			av_free_packet(videoCtx-&gt;packet);
		} else if (videoCtx-&gt;packet-&gt;stream_index == audioIndex) {
//			LOGE("Did we get a audio frame");
			decodeAudio(audioCtx, videoCtx-&gt;packet);
		} else {
			av_free_packet(videoCtx-&gt;packet);
		}

		SDL_PollEvent(&amp;videoCtx-&gt;event);
		switch (videoCtx-&gt;event.type) {
		case SDL_QUIT:
			quit = 1;
			SDL_Quit();
			exit(0);
			break;
		default:
			break;
		}
	}

	SDL_DestroyTexture(videoCtx-&gt;bmp);
	// Free the YUV frame
	av_free(videoCtx-&gt;pFrame);
	av_free(videoCtx-&gt;pFrameYUV);
	// Close the codec
	avcodec_close(videoCtx-&gt;codec_ctx);
	// Close the video file
	avformat_close_input(&amp;videoCtx-&gt;pFormatCtx);
	free(videoCtx);

	//		SDL_Window *window;
	//		SDL_Renderer *renderer;
	//
	//		if (SDL_CreateWindowAndRenderer(0, 0, 0, &amp;window, &amp;renderer) &lt; 0)
	//			exit(2);
	//
	//		Sprite sprite = LoadSprite("image.bmp", renderer);
	//		if (sprite.texture == NULL)
	//			exit(2);

	/* Main render loop */
	//	Uint8 done = 0;
	//	SDL_Event event;
	//	while (!done) {
	//		/* Check for events */
	//		while (SDL_PollEvent(&amp;event)) {
	//			if (event.type == SDL_QUIT || event.type == SDL_KEYDOWN
	//					|| event.type == SDL_FINGERDOWN) {
	//				done = 1;
	//			}
	//		}
	//			/* Draw a gray background */
	//			SDL_SetRenderDrawColor(renderer, 0xA0, 0xA0, 0xA0, 0xFF);
	//			SDL_RenderClear(renderer);
	//
	//			draw(window, renderer, sprite);
	//
	//			/* Update the screen! */
	//			SDL_RenderPresent(renderer);
	//
	//			SDL_Delay(10);
	//	}
	return 0;
}
</pre>
目前只解码了视频，音频尚有问题，Android.mk
<pre class="html">LOCAL_PATH := $(call my-dir)

include $(CLEAR_VARS)
LOCAL_MODULE:= avcodec-prebuilt-armeabi
LOCAL_SRC_FILES:= ../ffmpeg/arm/lib/libavcodec-57.so
include $(PREBUILT_SHARED_LIBRARY)

include $(CLEAR_VARS)
LOCAL_MODULE:= avdevice-prebuilt-armeabi
LOCAL_SRC_FILES:= ../ffmpeg/arm/lib/libavdevice-57.so
include $(PREBUILT_SHARED_LIBRARY)

include $(CLEAR_VARS)
LOCAL_MODULE:= avfilter-prebuilt-armeabi
LOCAL_SRC_FILES:= ../ffmpeg/arm/lib/libavfilter-6.so
include $(PREBUILT_SHARED_LIBRARY)

include $(CLEAR_VARS)
LOCAL_MODULE:= avformat-prebuilt-armeabi
LOCAL_SRC_FILES:= ../ffmpeg/arm/lib/libavformat-57.so
include $(PREBUILT_SHARED_LIBRARY)

include $(CLEAR_VARS)
LOCAL_MODULE :=  avutil-prebuilt-armeabi
LOCAL_SRC_FILES := ../ffmpeg/arm/lib/libavutil-55.so
include $(PREBUILT_SHARED_LIBRARY)

include $(CLEAR_VARS)
LOCAL_MODULE := swresample-prebuilt-armeabi
LOCAL_SRC_FILES := ../ffmpeg/arm/lib/libswresample-2.so
include $(PREBUILT_SHARED_LIBRARY)

include $(CLEAR_VARS)
LOCAL_MODULE := swscale-prebuilt-armeabi
LOCAL_SRC_FILES := ../ffmpeg/arm/lib/libswscale-4.so
include $(PREBUILT_SHARED_LIBRARY)

include $(CLEAR_VARS)

LOCAL_MODULE := main

SDL_PATH := ../SDL

LOCAL_C_INCLUDES := $(LOCAL_PATH)/$(SDL_PATH)/include
LOCAL_C_INCLUDES += -L$(SYSROOT)/usr/include
LOCAL_C_INCLUDES += $(LOCAL_PATH)/../ffmpeg/arm/include

# Add your application source files here...
LOCAL_SRC_FILES := $(SDL_PATH)/src/main/android/SDL_android_main.c \
	main.c

LOCAL_SHARED_LIBRARIES := SDL2 \
			 avcodec-prebuilt-armeabi \
                         avdevice-prebuilt-armeabi \
                         avfilter-prebuilt-armeabi \
                         avformat-prebuilt-armeabi \
                         avutil-prebuilt-armeabi \
                         swresample-prebuilt-armeabi \
                         swscale-prebuilt-armeabi

LOCAL_LDLIBS := -lGLESv1_CM -lGLESv2 -llog

include $(BUILD_SHARED_LIBRARY)
</pre>
SDLActivity里边修改
<pre class="html">protected String[] getLibraries() {
        return new String[] {
        	"avcodec-57",
        	"avdevice-57",
        	"avfilter-6",
        	"avformat-57",
        	"avutil-55",
        	"swresample-2",
        	"swscale-4",
            "SDL2",
            // "SDL2_image",
            // "SDL2_mixer",
            // "SDL2_net",
            // "SDL2_ttf",
            "main"
        };
    }</pre>
<pre class="html">//我直接传了个sd卡里边的一个视频 
protected String[] getArguments() {
        return new String[]{Environment.getExternalStorageDirectory() + File.separator + "hello.flv"};
    }</pre>
编译运行
![](http://img.blog.csdn.net/20160518112113396?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)